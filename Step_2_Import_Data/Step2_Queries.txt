Search Query 1: search=AI
Result for Query 1: { "@odata.context": "https://enriched-course-catalog-search.search.windows.net/indexes('courses-index')/$metadata#docs(*)", "value": [ { "@search.score": 3.3010633, "Key": "ms-learn0197c8c6-dfc4-450b-9fa7-3f610977cc79", "description": "Learn about AI Builder Text recognition and how to use it with other Power Platform products.", "duration": 55, "instructor": "", "level": "beginner", "product": "ai-builder", "rating_average": 4.61, "rating_count": 197, "role": "business-user", "source": "MS Learn", "title": "Get started with AI Builder Text recognition", "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-text-recognition/?WT.mc_id=api_CatalogApi", "keyphrases": [ "AI Builder Text recognition", "other Power Platform products" ], "instructor_data": null, "entities": null }, { "@search.score": 2.2539883, "Key": "ms-learn002f4436-7360-4daa-a21d-f9dcd3518589", "description": "Enable business users with key AI use cases", "duration": 34, "instructor": "", "level": "beginner", "product": "power-platform", "rating_average": 4.75, "rating_count": 758, "role": "functional-consultant", "source": "MS Learn", "title": "Enable business users with key AI use cases", "url": "https://docs.microsoft.com/en-us/learn/modules/enable-business-users-with-key-ai-uses-cases/?WT.mc_id=api_CatalogApi", "keyphrases": [ "key AI use cases", "business users" ], "instructor_data": null, "entities": null }, { "@search.score": 0.78241664, "Key": "ms-learn00baaa75-89fe-4f86-805f-f08336e6af48", "description": "Explore the strategic components, use cases, and special factors of an enterprise AI strategy that creates real business value, with INSEAD and Microsoft.", "duration": 70, "instructor": "", "level": "intermediate", "product": "m365", "rating_average": 4.71, "rating_count": 2779, "role": "business-user", "source": "MS Learn", "title": "Define an AI strategy to create business value", "url": "https://docs.microsoft.com/en-us/learn/modules/ai-strategy-to-create-business-value/?WT.mc_id=api_CatalogApi", "keyphrases": [ "enterprise AI strategy", "real business value", "strategic components", "special factors", "cases", "INSEAD", "Microsoft" ], "instructor_data": null, "entities": null }, { "@search.score": 0.5377023, "Key": "ms-learn01731c10-20bb-41e7-ba21-8528669dcdc3", "description": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps", "duration": 18, "instructor": "", "level": "advanced", "product": "azure", "rating_average": 4.75, "rating_count": 137, "role": "ai-engineer", "source": "MS Learn", "title": "Use containers for your Language Understanding Intelligent Service (LUIS) Apps", "url": "https://docs.microsoft.com/en-us/learn/modules/use-containers-language-understanding-intelligent-service-apps/?WT.mc_id=api_CatalogApi", "keyphrases": [ "Language Understanding Intelligent Service", "LUIS) Apps", "containers" ], "instructor_data": null, "entities": null }, { "@search.score": 0.4253103, "Key": "company-moodle6b5d3f55-eb02-499d-9775-2e0e25659e07", "description": "Learn our company's Principles for the Responsible Use of AI", "duration": 1, "instructor": "Eileen Diaz", "level": "intermediate", "product": "NA", "rating_average": 4.3, "rating_count": 24, "role": "architect", "source": "Company Moodle", "title": "Ethics in AI", "url": "https://www.example.com/course12", "keyphrases": [ "Responsible Use", "company", "Principles", "AI" ], "instructor_data": null, "entities": null } ] }

Search Query 2: search="Privacy preservation"
Results of Query 2: { "@odata.context": "https://enriched-course-catalog-search.search.windows.net/indexes('papers-index')/$metadata#docs(*)", "value": [ { "@search.score": 1.7842643, "content": "\nPrivacy preservation techniques in big \ndata analytics: a survey\nP. Ram Mohan Rao1,4*, S. Murali Krishna2 and A. P. Siva Kumar3\n\nIntroduction\nThere is an exponential growth in volume and variety of data as due to diverse applica-\ntions of computers in all domain areas. The growth has been achieved due to afford-\nable availability of computer technology, storage, and network connectivity. The large \nscale data, which also include person specific private and sensitive data like gender, zip \ncode, disease, caste, shopping cart, religion etc. is being stored in public domain. The \ndata holder can release this data to a third party data analyst to gain deeper insights and \nidentify hidden patterns which are useful in making important decisions that may help \nin improving businesses, provide value added services to customers [1], prediction, fore-\ncasting and recommendation [2]. One of the prominent applications of data analytics is \nrecommendation systems which is widely used by ecommerce sites like Amazon, Flip \nkart for suggesting products to customers based on their buying habits. Face book does \nsuggest friends, places to visit and even movie recommendation based on our interest. \nHowever releasing user activity data may lead inference attacks like identifying gender \nbased on user activity [3]. We have studied a number of privacy preserving techniques \nwhich are being employed to protect against privacy threats. Each of these techniques \nhas their own merits and demerits. This paper explores the merits and demerits of each \n\nAbstract \n\nIncredible amounts of data is being generated by various organizations like hospitals, \nbanks, e-commerce, retail and supply chain, etc. by virtue of digital technology. Not \nonly humans but machines also contribute to data in the form of closed circuit televi-\nsion streaming, web site logs, etc. Tons of data is generated every minute by social \nmedia and smart phones. The voluminous data generated from the various sources \ncan be processed and analyzed to support decision making. However data analytics \nis prone to privacy violations. One of the applications of data analytics is recommen-\ndation systems which is widely used by ecommerce sites like Amazon, Flip kart for \nsuggesting products to customers based on their buying habits leading to inference \nattacks. Although data analytics is useful in decision making, it will lead to serious \nprivacy concerns. Hence privacy preserving data analytics became very important. This \npaper examines various privacy threats, privacy preservation techniques and models \nwith their limitations, also proposes a data lake based modernistic privacy preservation \ntechnique to handle privacy preservation in unstructured data.\n\nKeywords: Data, Data analytics, Privacy threats, Privacy preservation\n\nOpen Access\n\n© The Author(s) 2018. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nRam Mohan Rao et al. J Big Data (2018) 5:33 \nhttps://doi.org/10.1186/s40537-018-0141-8\n\n*Correspondence: \nrammohan04@gmail.com \n1 Department of Computer \nScience and Engineering, \nMLR Institute of Technology, \nHyderabad, India\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-018-0141-8&domain=pdf\n\n\nPage 2 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nof these techniques and also describes the research challenges in the area of privacy \npreservation. Always there exists a trade off between data utility and privacy. This paper \nalso proposes a data lake based modernistic privacy preservation technique to handle \nprivacy preservation in unstructured data with maximum data utility.\n\nPrivacy threats in data analytics\nPrivacy is the ability of an individual to determine what data can be shared, and employ \naccess control. If the data is in public domain then it is a threat to individual privacy \nas the data is held by data holder. Data holder can be social networking application, \nwebsites, mobile apps, ecommerce site, banks, hospitals etc. It is the responsibility of \nthe data holder to ensure privacy of the users data. Apart from the data held in public \ndomain, knowing or unknowingly users themself contribute to data leakage. For exam-\nple most of the mobile apps, seek access to our contacts, files, camera etc. and without \nreading the privacy statement we agree for all terms and conditions, there by contribut-\ning to data leakage.\n\nHence there is a need to educate the smart phone users regarding privacy and privacy \nthreats. Some of the key privacy threats include (1) Surveillance; (2) Disclosure; (3) Dis-\ncrimination; (4) Personal embracement and abuse.\n\nSurveillance\n\nMany organizations including retail, e-commerce, etc. study their customers buying \nhabits and try to come up with various offers and value added services [4]. Based on the \nopinion data and sentiment analysis, social media sites does provide recommendations \nof the new friends, places to visit, people to follow etc. This is possible only when they \ncontinuously monitor their customer’s transactions. This is a serious privacy threat as no \nindividual accepts surveillance.\n\nDisclosure\n\nConsider a hospital holding patient’s data which include (Zip, gender, age, disease) [5–7]. \nThe data holder has released data to a third party for analysis by anonymizing sensitive \nperson specific data so that the person cannot be identified. The third party data analyst \ncan map this information with the freely available external data sources like census data \nand can identify person suffering with some disorder. This is how private information of \na person can be disclosed which is considered to be a serious privacy breach.\n\nDiscrimination\n\nDiscrimination is the bias or inequality which can happen when some private informa-\ntion of a person is disclosed. For instance, statistical analysis of electoral results proved \nthat people of one community were completely against the party, which formed the gov-\nernment. Now the government can neglect that community or can have bias over them.\n\nPersonal embracement and abuse\n\nWhenever some private information of a person is disclosed, it can even lead to per-\nsonal embracement or abuse. For example, a person was privately undergoing medica-\ntion for some specific problem and was buying some medicines on a regular basis from a \n\n\n\nPage 3 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nmedical shop. As part of their regular business model, the medical shop may send some \nreminder and offers related to these medicines over phone. If any family member has \nnoticed this, it will lead to personal embracement and even abuse [8].\n\nData analytics activity will affect data Privacy. Many countries are enforcing Privacy \npreservation laws. Lack of awareness is also a major reason for privacy attacks. For \nexample many smart phones users are not aware of the information that is stolen from \ntheir phones by many apps. Previous research shows only 17% of smart phone users are \naware of privacy threats [9].\n\nPrivacy preservation methods\nMany Privacy preserving techniques were developed, but most of them are based on \nanonymization of data. The list of privacy preservation techniques is given below.\n\n • K anonymity\n • L diversity\n • T closeness\n • Randomization\n • Data distribution\n • Cryptographic techniques\n • Multidimensional Sensitivity Based Anonymization (MDSBA).\n\nK anonymity [10]\n\nAnonymization is the process of modifying data before it is given for data analytics [11], \nso that de identification is not possible and will lead to K indistinguishable records if \nan attempt is made to de identify by mapping the anonymized data with external data \nsources. K anonymity is prone to two attacks namely homogeneity attack and back \nground knowledge attack. Some of the algorithms applied include, Incognito [12], Mon-\ndrian [13] to ensure Anonymization. K anonymity is applied on the patient data shown \nin Table 1. The table shows data before anonymization.\n\nK anonymity algorithm is applied with k value as 3 to ensure 3 indistinguishable \nrecords when an attempt is made to identify a particular person’s data. K anonymity is \napplied on the two attributes viz. Zip and age shown in Table 1. The result of applying \nanonymization on Zip and age attributes is shown in Table 2.\n\nTable 1 Patient data, before anonymization\n\nSno Zip Age Disease\n\n1 57677 29 Cardiac problem\n\n2 57602 22 Cardiac problem\n\n3 57678 27 Cardiac problem\n\n4 57905 43 Skin allergy\n\n5 57909 52 Cardiac problem\n\n6 57906 47 Cancer\n\n7 57605 30 Cardiac problem\n\n8 57673 36 Cancer\n\n9 57607 32 Cancer\n\n\n\nPage 4 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nThe above technique has used generalization [14] to achieve Anonymization. Suppose \nif we know that John is 27 year old and lives in 57677 zip codes then we can conclude \nJohn to have Cardiac problem even after anonymization as shown in Table  2. This is \ncalled Homogeneity attack. For example if John is 36 year old and it is known that John \ndoes not have cancer, then definitely John must have Cardiac problem. This is called as \nbackground knowledge attack. Achieving K anonymity [15, 16] can be done either by \nusing generalization or suppression. K anonymity can optimized if the minimal gener-\nalization can be done without huge data loss [17]. Identity disclosure is the major pri-\nvacy threat which cannot be guaranteed by K anonymity [18]. Personalized privacy is the \nmost important aspect of individual privacy [19].\n\nL diversity\n\nTo address homogeneity attack, another technique called L diversity has been proposed. \nAs per L diversity there must be L well represented values for the sensitive attribute (dis-\nease) in each equivalence class.\n\nImplementing L diversity is not possible every time because of the variety of data. L \ndiversity is also prone to skewness attack. When overall distribution of data is skewed \ninto few equivalence classes attribute disclosure cannot be ensured. For example if the \nentire records are distributed into only three equivalence classes then semantic close-\nness of these values may lead to attribute disclosure. Also L diversity may lead to simi-\nlarity attack. From Table 3 it can be noticed that if we know that John is 27 year old and \nlives in 57677 zip, then definitely John is under low income group because salaries of all \n\nTable 2 After applying anonymization on Zip and age\n\nSno Zip Age Disease\n\n1 576** 2* Cardiac problem\n\n2 576** 2* Cardiac problem\n\n3 576** 2* Cardiac problem\n\n4 5790* > 40 Skin allergy\n\n5 5790* > 40 Cardiac problem\n\n6 5790* > 40 Cancer\n\n7 576** 3* Cardiac problem\n\n8 576** 3* Cancer\n\n9 576** 3* Cancer\n\nTable 3 L diversity privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 6k Cardiac problem\n\n3 576** 2* 7k Cardiac problem\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 22k Cardiac problem\n\n6 5790* > 40 24k Cancer\n\n\n\nPage 5 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nthree persons in 576** zip is low compare to others in the table. This is called as similar-\nity attack.\n\nT closeness\n\nAnother improvement to L diversity is T closeness measure where an equivalence class \nis considered to have ‘T closeness’ if the distance between the distributions of sensi-\ntive attribute in the class is no more than a threshold and all equivalence classes have T \ncloseness [20]. T closeness can be calculated on every attribute with respect to sensitive \nattribute.\n\nFrom Table 4 it can be observed that if we know John is 27 year old, still it will be dif-\nficult to estimate whether John has Cardiac problem or not and he is under low income \ngroup or not. T closeness may ensure attribute disclosure but implementing T closeness \nmay not give proper distribution of data every time.\n\nRandomization technique\n\nRandomization is the process of adding noise to the data which is generally done by \nprobability distribution [21]. Randomization is applied in surveys, sentiment analy-\nsis etc. Randomization does not need knowledge of other records in the data. It can be \napplied during data collection and pre processing time. There is no anonymization over-\nhead in randomization. However, applying randomization on large datasets is not possi-\nble because of time complexity and data utility which has been proved in our experiment \ndescribed below.\n\nWe have loaded 10k records from an employee database into Hadoop Distributed File \nSystem and processed them by executing a Map Reduce Job. We have experimented to \nclassify the employees based on their salary and age groups. In order apply randomiza-\ntion we added noise in the form of 5k records which are randomly added to make a data-\nbase of 15k records and following observations were made after running Map Reduce \njob.\n\n • More number of Mappers and Reducers were used as data volume increased.\n • Results before and after randomization were significantly different.\n • Some of the records which are outliers remain unaffected with randomization and \n\nare vulnerable to adversary attack.\n • Privacy preservation at the cost of data utility is not appreciated and hence randomi-\n\nzation may not be suitable for privacy preservation especially attribute disclosure.\n\nTable 4 T closeness privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 16k Cancer\n\n3 576** 2* 9k Skin allergy\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 42k Cardiac problem\n\n6 5790* > 40 8k Flu\n\n\n\nPage 6 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nData distribution technique\n\nIn this technique, the data is distributed across many sites. Distribution of the data can \nbe done in two ways:\n\ni. Horizontal distribution of data\nii. Vertical distribution of data\n\nHorizontal distribution When data is distributed across many sites with same attrib-\nutes then the distribution is said to be horizontal distribution which is described in \nFig. 1.\n\nHorizontal distribution of data can be applied only when some aggregate functions or \noperations are to be applied on the data without actually sharing the data. For example, \nif a retail store wants to analyse their sales across various branches, they may employ \nsome analytics which does computations on aggregate data. However, as part of data \nanalysis the data holder may need to share the data with third party analyst which may \nlead to privacy breach. Classification and Clustering algorithms can be applied on dis-\ntributed data but it does not ensure privacy. If the data is distributed across different \nsites which belong to different organizations, then results of aggregate functions may \nhelp one party in detecting the data held with other parties. In such situations we expect \nall participating sites to be honest with each other [21].\n\nVertical distribution of data When Person specific information is distributed across \ndifferent sites under custodian of different organizations, then the distribution is called \nvertical distribution as shown in Fig. 2. For example, in crime investigations, the police \nofficials would like to know details of a particular criminal which include health, profes-\nsion, financial, personal etc. All this information may not be available at one site. Such a \ndistribution is called vertical distribution where each site holds few set of attributes of a \nperson. When some analytics has to be done data has to be pooled in from all these sites \nand there is a vulnerability of privacy breach.\n\nIn order to perform data analytics on vertically distributed data, where the attributes \nare distributed across different sites under custodian of different parties, it is highly \n\nFig. 1 Distribution of sales data across different sites\n\n\n\nPage 7 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\ndifficult to ensure privacy if the datasets are shared. For example, as part of a police \ninvestigation, the investigating officer wants to access some information about the \naccused from his employer, health department, bank to gain more insights about the \ncharacter of the person. In this process some of the personal and sensitive information \nof the accused may be disclosed to investigating officer leading to personal embarrass-\nment or abuse. Anonymization cannot be applied when entire records are not needed \nfor analytics. Distribution of data will not ensure privacy preservation but it closely \noverlaps with cryptographic techniques.\n\nCryptographic techniques\n\nThe data holder may encrypt the data before releasing the same for analytics. But \nencrypting large scale data using conventional encryption techniques is highly difficult \nand must be applied only during data collection time. Differential privacy techniques \nhave already been applied where some aggregate computations on the data are done \nwithout actually sharing the inputs. For example, if x and y are two data items then a \nfunction F(x, y) will be computed to gain some aggregate information from both x and \ny without actually sharing x and y. This can be applied on when x and y are held with \ndifferent parties as in the case of vertical distribution. However, if the data is at single \nlocation under the custodian of a single organization, then differential privacy can-\nnot be employed. Another similar technique called secure multiparty computation has \nbeen used but proved to be inadequate in privacy preservation. Data utility will be less \nif encryption is applied during data analytics. Thus encryption is not only difficult to \nimplement but it reduces the data utility [22].\n\nMultidimensional Sensitivity Based Anonymization (MDSBA)\n\nBottom up Generalization [23] and Top down Generalization [24] are the conventional \nmethods of Anonymization which were applied on well represented structured data \nrecords. However, applying the same on large scale data sets is very difficult leading to \n\nFig. 2 Vertical distribution of person specific data\n\n\n\nPage 8 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nissues of scalability and information loss. Multidimensional Sensitivity Based Anonymi-\nzation is a improved version of Anonymization proved to be more effective than conven-\ntional Anonymization techniques.\n\nMultidimensional Sensitivity Based Anonymization is an improved Anonymization \n[25] technique such that it can be applied on large data sets with reduced loss of informa-\ntion and predefined quasi identifiers. As part of this technique Apache MAP REDUCE \n[26] framework has been used to handle large data sets. In conventional Hadoop Distrib-\nuted Files System, the data will be divided into blocks of either 64 MB or 128 MB each \nand distributed across different nodes without considering the data inside the blocks. \nAs part of Multidimensional Sensitivity Based Anonymization [27] technique the data is \nsplit into different bags based on the probability distribution of the quasi identifiers by \nmaking use of filters in Apache Pig scripting language.\n\nMultidimensional Sensitivity Based Anonymization makes use of bottom up generali-\nzation but on a set of attributes with certain class values where class represents a sensi-\ntive attributes. Data distribution was made effectively when compared to conventional \nmethod of blocks. Data Anonymization was done using four quasi identifiers using \nApache Pig.\n\nSince the data is vertically partitioned into different groups, it can protect from back-\nground knowledge attack if the bag contains only few attributes. This method also \nmakes it difficult to map the data with external sources to disclose any person specific \ninformation.\n\nIn this method, the implementation was done using Apache Pig. Apache Pig is a script-\ning language, hence development effort is less. However, code efficiency of Apache Pig is \nrelatively less when compared to Map Reduce job because ultimately every Apache Pig \nscript has to be converted into a Map Reduce job. Multidimensional Sensitivity Based \nAnonymization [28] is more appropriate for large scale data but only when the data is at \nrest. Multidimensional Sensitivity Based Anonymization cannot be applied for stream-\ning data.\n\nAnalysis\nVarious privacy preservation techniques have been studied with respect to features \nincluding, type of data, data utility, attribute preservation and complexity. The compari-\nson of various privacy preservation techniques is shown in Table 5.\n\nTable 5 Comparison of privacy preservation techniques\n\nFeatures Privacy preservation techniques\n\nAnonymization \ntechniques\n\nCryptographic \ntechniques\n\nData \ndistribution\n\nRandomization MDSBA\n\nSuitability for unstructured data No No No No Yes\n\nAttribute preservation No No No Yes Yes\n\nDamage to data utility No No Yes No Yes\n\nVery complex to apply No Yes Yes Yes Yes\n\nAccuracy of results of data \nanalytics\n\nNo Yes No No No\n\n\n\nPage 9 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nResults and discussions\nAs part of systematic literature review, it has been observed that all existing mecha-\nnisms of privacy preservation are with respect to structured data. More than 80% of data \nbeing generated today is unstructured [29]. As such, there is a need to address following \nchallenges.\n\ni. Develop concrete solution to protect privacy in both structured and unstructured \ndata.\n\nii. Scalable and robust techniques to be developed to handle large scale heterogeneous \ndata sets.\n\niii. Data should be allowed to stay in its native form without need for transformation \nand data analytics can be carried out while ensuring privacy preservation.\n\niv. New techniques apart from Anonymization must be developed to ensure protection \nagainst key privacy threats which include identity disclosure, discrimination, surveil-\nlance etc.\n\nv. Maximizing data utility while ensuring data privacy.\n\nConclusion\nNo concrete solution for unstructured data has been developed yet. Conventional \ndata mining algorithms can be applied for classification and clustering problems but \ncannot be used in privacy preservation especially when dealing with person specific \ninformation. Machine learning and soft computing techniques can be used to develop \nnew and more appropriate solution to privacy problems which include identity dis-\nclosure that can lead to personal embarrassment and abuse.\n\nThere is a strong need for law enforcement by governments of all countries to \nensure individual privacy. European Union [30] is making an attempt to enforce pri-\nvacy preservation law. Apart from technological solutions, there is a strong need to \ncreate awareness among the people regarding privacy hazards to safeguard them-\nselves form privacy breaches. One of the serious privacy threats is smart phone. Lot \nof personal information in the form of contacts, messages, chats and files are being \naccessed by many apps running in our smart phone without our knowledge. Most \nof the time people do not even read the privacy statement before installing any app. \nHence there is a strong need to educate people on the various vulnerabilities which \ncan contribute to leakage of private information.\n\nWe propose a novel privacy preservation model based on Data Lake concept to \nhold variety of data from diverse sources. Data lake is a repository to hold data from \ndiverse sources in their raw format [31, 32]. Data ingestion from variety of sources can \nbe done using Apache Flume and an intelligent algorithm based on machine learning \ncan be applied to identify sensitive attributes dynamically [33, 34]. The algorithm will \nbe trained with existing data sets with known sensitive attributes and rigorous train-\ning of the model will help in predicting the sensitive attributes in a given data set [35]. \nAccuracy of the model can be improved by adding more layers of training leading \nto deep learning techniques [36]. Advanced computing techniques like Apache Spark \ncan be used in implementing privacy preserving algorithms which is a distributed \n\n\n\nPage 10 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nmassive parallel computing with in memory processing to ensure very fast processing \n[37]. The proposed model is shown in Fig. 3.\n\nData analytics is done on the data collected from various sources. If an ecommerce \nsite would like to perform data analytics, they need transactional data, website logs and \ncustomers opinion through social media pages. A Data lake is used to collect data from \ndifferent sources. Apache Flume is used to ingest data from social media sites, website \nlogs into Hadoop Distributed File System(HDFS). Using SQOOP relational data can be \nloaded into HDFS.\n\nIn Data lake the data can remain in its native form which is either structured or \nunstructured. When data has to be processed, it can be transformed into HIVE tables. A \nHadoop map reduce job using machine learning can be executed on the data to classify \nthe sensitive attributes [38]. The data can be vertically distributed to separate the sensi-\ntive attributes from rest of the data and apply tokenization to map the vertically distrib-\nuted data. The data without any sensitive attributes can be published for data analytics.\n\nAbbreviations\nCCTV: closed circuit television; MDSBA: Multidimensional Sensitivity Based Anonymization.\n\nAuthors’ contributions\nPRMR: as part of Ph.D. work I have done my literature survey and submitted my work in the form of a paper. SMK: \nsupported me in compiling the paper. APSK: suggested necessary amendments and helped in revising the paper. All \nauthors read and approved the final manuscript.\n\nAuthor details\n1 Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad, India. 2 Department \nof Computer Science and Engineering, Sri Venkateswara College of Engineering, Tirupati, Andhra Pradesh, India. \n3 Department of Computer Science and Engineering, JNTU Anantapur, Anantapuramu, Andhra Pradesh, India. 4 JNTU \nAnantapur, Anantapur, Andhra Pradesh, India. \n\nAcknowledgements\nI would like to thank my guides, for supporting my work and for suggesting necessary corrections.\n\nData Lake\n\nSqoop to load data from RDBMS\n\nApache \nFlume \nto load \nsocial \nmedia \ndata\n\nLoad data from\ndifferent sources\nand varie es into\nHive Table for\nprocessing\n\nHadoop\nMap\nReduce\nJob to\nclassify\nsensi ve\ndata\n\nNovel Privacy \nPreserva on \nalgorithm \nbased on \nver cal \ndistribu on and \ntokeniza on\n\nFig. 3 A Novel privacy preservation model based on vertical distribution and tokenization\n\n\n\nPage 11 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nIf any one is interested in our work, we are ready to provide more details of the map reduce job which we have \nexecuted and the data processing techniques applied. However the data is used in our work, is freely available in many \nrepositories.\n\nFunding\nNo Funding.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 21 March 2018 Accepted: 4 September 2018\n\nReferences\n 1. Ducange Pietro, Pecori Riccardo, Mezzina Paolo. A glimpse on big data analytics in the framework of marketing \n\nstrategies. Soft Comput. 2018;22(1):325–42.\n 2. Chauhan Arun, Kummamuru Krishna, Toshniwal Durga. Prediction of places of visit using tweets. Knowl Inf Syst. \n\n2017;50(1):145–66.\n 3. Yang D, Bingqing Q, Cudre-Mauroux P. Privacy-preserving social media data publishing for personalized ranking-\n\nbased recommendation. IEEE Trans Knowl Data Eng. 2018. ISSN (Print):1041-4347, ISSN (Electronic):1558-2191.\n 4. Liu Y et al. A practical privacy-preserving data aggregation (3PDA) scheme for smart grid. IEEE Trans Ind Inf. 2018.\n 5. Duncan GT et al. Disclosure limitation methods and information loss for tabular data. In: Confidentiality, disclosure \n\nand data access: theory and practical applications for statistical agencies. 2001. p. 135–166.\n 6. Duncan GT, Diane L. Disclosure-limited data dissemination. J Am Stat Assoc. 1986;81(393):10–8.\n 7. Lambert Diane. Measures of disclosure risk and harm. J Off Stat. 1993;9(2):313.\n 8. Spiller K, et al. Data privacy: users’ thoughts on quantified self personal data. Self-Tracking. Cham: Palgrave Macmil-\n\nlan; 2018. p. 111–24.\n 9. Hettig M, Kiss E, Kassel J-F, Weber S, Harbach M. Visualizing risk by example: demonstrating threats arising from \n\nandroid apps. In: Smith M, editor. Symposium on usable privacy and security (SOUPS), Newcastle, UK, July 24–26, \n2013.\n\n 10. Bayardo RJ, Agrawal A. Data privacy through optimal k-anonymization. In: Proceedings 21st international confer-\nence on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 11. Iyengar S. Transforming data to satisfy privacy constraints. In: Proceedings of the eighth ACM SIGKDD international \nconference on knowledge discovery and data mining. New York: ACM; 2002.\n\n 12. LeFevre K, DeWitt DJ, Ramakrishnan R. Incognito: efficient full-domain k-anonymity. In: Proceedings of the 2005 \nACM SIGMOD international conference on management of data. New York: ACM; 2005.\n\n 13. LeFevre K, DeWitt DJ, Ramakrishnan R. Mondrian multidimensional k-anonymity. In: Proceedings of the 22nd inter-\nnational conference (ICDE’06) on data engineering, 2006. New York: ACM; 2006.\n\n 14. Samarati, Pierangela, and Latanya Sweeney. In: Protecting privacy when disclosing information: k-anonymity and its \nenforcement through generalization and suppression. Technical report, SRI International, 1998.\n\n 15. Sweeney Latanya. Achieving k-anonymity privacy protection using generalization and suppression. In J Uncertain \nFuzziness Knowl Based Syst. 2002;10(05):571–88.\n\n 16. Sweeney Latanya. k-Anonymity: a model for protecting privacy. Int J Uncertain, Fuzziness Knowl Based Syst. \n2002;10(05):557–70.\n\n 17. Williams R. On the complexity of optimal k-anonymity. In: Proc. 23rd ACM SIGMOD-SIGACT-SIGART symp. principles \nof database systems (PODS). New York: ACM; 2004.\n\n 18. Machanavajjhala A et al. L-diversity: privacy beyond k-anonymity. In: Proceedings of the 22nd international confer-\nence on data engineering (ICDE’06), 2006. Piscataway: IEEE; 2006.\n\n 19. Xiao X, Yufei T. Personalized privacy preservation. In: Proceedings of the 2006 ACM SIGMOD international confer-\nence on Management of data. New York: ACM; 2006.\n\n 20. Rubner Y, Tomasi T, Guibas LJ. The earth mover’s distance as a metric for image retrieval. Int J Comput Vision. \n2000;40(2):99–121.\n\n 21. Aggarwal CC, Philip SY. A general survey of privacy-preserving data mining models and algorithms. Privacy-preserv-\ning data mining. Springer: US; 2008. p. 11–52.\n\n 22. Jiang R, Lu R, Choo KK. Achieving high performance and privacy-preserving query over encrypted multidimensional \nbig metering data. Future Gen Comput Syst. 2018;78:392–401.\n\n 23. Wang K, Yu PS, Chakraborty S. Bottom-up generalization: A data mining solution to privacy protection. In: Fourth \nIEEE international conference on data mining, 2004 (ICDM’04). Piscataway: IEEE; 2004.\n\n 24. Fung BCM, Wang K, Yu PS. Top-down specialization for information and privacy preservation. In: Proceedings 21st \ninternational conference on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 25. Zhang X et al. A MapReduce based approach of scalable multidimensional anonymization for big data privacy \npreservation on cloud. In: Third international conference on cloud and green computing (CGC), 2013. Piscataway: \nIEEE; 2013.\n\n\n\nPage 12 of 12Ram Mohan Rao et al. J Big Data (2018) 5:33 \n\n 26. Zhang X, et al. A scalable two-phase top-down specialization approach for data anonymization using mapreduce \non cloud. IEEE Trans Parallel Distrib Syst. 2014;25(2):363–73.\n\n 27. Al-Zobbi M, Shahrestani S, Ruan C. Improving MapReduce privacy by implementing multi-dimensional sensitivity-\nbased anonymization. J Big Data. 2017;4(1):45.\n\n 28. Al-Zobbi M, Shahrestani S, Ruan C. Implementing a framework for big data anonymity and analytics access control. \nIn: Trustcom/BigDataSE/ICESS, 2017 IEEE. Piscataway: IEEE; 2017.\n\n 29. Schneider C. IBM Blogs; 2016. https ://www.ibm.com/blogs /watso n/2016/05/bigge st-data-chall enges -might \n-not-even-know/.\n\n 30. TCS. Emphasizing the need for government regulations on data privacy; 2016. https ://www.tcs.com/conte nt/dam/\ntcs/pdf/techn ologi es/Cyber -Secur ity/Abstr act/Stren gthen ing-Priva cy-Prote ction -with-the-Europ ean-Gener al-Data-\nProte ction -Regul ation .pdf.\n\n 31. He X, et al. Qoe-driven big data architecture for smart city. IEEE Commun Mag. 2018;56(2):88–93.\n 32. Ramakrishnan R et al. Azure data lake store: a hyperscale distributed file service for big data analytics. In: Proceed-\n\nings of the 2017 ACM international conference on management of data. New York: ACM; 2017.\n 33. Beheshti A et al. Coredb: a data lake service. In: Proceedings of the 2017 ACM on conference on information and \n\nknowledge management. New York: ACM; 2017.\n 34. Shang T et al. A DP Canopy K-means algorithm for privacy preservation of Hadoop platform. In: International sym-\n\nposium on cyberspace safety and security. Cham: Springer; 2017.\n 35. Jia Q et al. Preserving model privacy for machine learning in distributed systems. IEEE Trans Parallel Distrib Syst. \n\n2018;29(8).\n 36. Psychoula I et al. A deep learning approach for privacy preservation in assisted living. arXiv preprint arXiv \n\n:1802.09359 . 2018.\n 37. Guller M. Big data analytics with spark: a practitioner’s guide to using spark for large scale data analysis. New York: \n\nApress; 2015.\n 38. Fung BCM, Wang K, Philip SY. Anonymzing classification data for privacy preservation. IEEE Trans Knowl Data Eng. \n\n2007;19(5):711–25.\n\nhttps://www.ibm.com/blogs/watson/2016/05/biggest-data-challenges-might-not-even-know/\nhttps://www.ibm.com/blogs/watson/2016/05/biggest-data-challenges-might-not-even-know/\nhttps://www.tcs.com/content/dam/tcs/pdf/technologies/Cyber-Security/Abstract/Strengthening-Privacy-Protection-with-the-European-General-Data-Protection-Regulation.pdf\nhttps://www.tcs.com/content/dam/tcs/pdf/technologies/Cyber-Security/Abstract/Strengthening-Privacy-Protection-with-the-European-General-Data-Protection-Regulation.pdf\nhttps://www.tcs.com/content/dam/tcs/pdf/technologies/Cyber-Security/Abstract/Strengthening-Privacy-Protection-with-the-European-General-Data-Protection-Regulation.pdf\nhttp://arxiv.org/abs/1802.09359\nhttp://arxiv.org/abs/1802.09359\n\n\tPrivacy preservation techniques in big data analytics: a survey\n\tAbstract \n\tIntroduction\n\tPrivacy threats in data analytics\n\tSurveillance\n\tDisclosure\n\tDiscrimination\n\tPersonal embracement and abuse\n\n\tPrivacy preservation methods\n\tK anonymity [10]\n\tL diversity\n\tT closeness\n\tRandomization technique\n\tData distribution technique\n\tCryptographic techniques\n\tMultidimensional Sensitivity Based Anonymization (MDSBA)\n\n\tAnalysis\n\tResults and discussions\n\tConclusion\n\tAuthors’ contributions\n\tReferences\n\n\n\n\n", "metadata_storage_path": "aHR0cHM6Ly9jb3Vyc2VjYXRhbG9nc3RvcmFnZW5yai5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDUzNy0wMTgtMDE0MS04LnBkZg2", "metadata_title": "Privacy preservation techniques in big data analytics: a survey", "keyphrases": [ "Privacy preservation techniques", "big data analytics", "survey" ], "pubication_name": null, "publishers": null, "doi": null, "publication_date": null }, { "@search.score": 1.4000542, "content": "\nMobile marketing recommendation method \nbased on user location feedback\nChunyong Yin1 , Shilei Ding1 and Jin Wang2*\n\nIntroduction\nIn recent years, the e-commerce industry has developed rapidly with the popularization \nof the Internet. At this time, famous e-commerce platforms such as Alibaba and Ama-\nzon were born. E-commerce moved physical store products to a virtual network plat-\nform. On the one hand, it is convenient for users to buy various products without leaving \nthe home. On the other hand, it is also convenient for sellers to sell their own goods \nand reduce costs. However, the various products have made it more difficult for users \nto select products. E-commerce platform can generate a large amount of user location \nfeedback data which contains a wealth of user preference information [1]. It is significant \nto predict the location of the next consumer’s consumption from these behavioral data. \nAt present, most of the recommended methods focus on the user-product binary matrix \nand directly model their binary relationships [2]. The users’ location information and \nshopping location information are considered as the third factor. In this case, you can \nonly use the limited check-in data. The users’ location feedback behavior and the timeli-\nness of behavior are often overlooked.\n\nThe mobile recommendation system takes advantage of the mobile network environ-\nment in terms of information recommendation and overcomes the disadvantages. Filter-\ning irrelevant information by predicting potential mobile user preferences and providing \n\nAbstract \n\nLocation-based mobile marketing recommendation has become one of the hot spots \nin e-commerce. The current mobile marketing recommendation system only treats \nlocation information as a recommended attribute, which weakens the role of users and \nshopping location information in the recommendation. This paper focuses on location \nfeedback data of user and proposes a location-based mobile marketing recommenda-\ntion model by convolutional neural network (LBCNN). First, the users’ location-based \nbehaviors are divided into different time windows. For each window, the extractor \nachieves users’ timing preference characteristics from different dimensions. Next, we \nuse the convolutional model in the convolutional neural network model to train a \nclassifier. The experimental results show that the model proposed in this paper is better \nthan the traditional recommendation models in the terms of accuracy rate and recall \nrate, both of which increase nearly 10%.\n\nKeywords: Location feedback, Mobile marketing, Convolutional neural network, \nSequential behavior\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nRESEARCH\n\nYin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \nhttps://doi.org/10.1186/s13673-019-0177-6\n\n*Correspondence: \njinwang@csust.edu.cn \n2 School of Computer & \nCommunication Engineering, \nChangsha University \nof Science & Technology, \nChangsha 410004, China\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-5764-2432\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13673-019-0177-6&domain=pdf\n\n\nPage 2 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nmobile users with results that meet users’ individual needs gradually become an effec-\ntive means to alleviate “mobile information overload” [3]. Mobile users have different \npreferences in different geographical locations. For this problem, how to use location \ninformation to obtain mobile users’ preferences and provide accurate personalized \nrecommendations has become a hot topic in mobile recommendation research [4]. \nAlthough there are many researches based on location recommendation, they mainly \nfocus on service resources without positional relevance. To solve the shortcomings of \nresearch on location relevance of service resources is few [5], Zhu et  al. [6] proposed \nthe method which is based on the user’s context information to analyze the user’s pref-\nerences and retrograde. Their approach is to derive user preferences by proposing two \ndifferent assumptions and then recommending user models based on preference analy-\nsis. Yin et al. [7] proposed LA-LDA. The method is a location-aware based generation \nprobability model, which uses scoring based on location to model user information and \nrecommend to users. However, these methods only treat location information as an \nattribute without considering the spatial information of users or items and weaken loca-\ntion information’s role in the recommendation. There are some studies determine user \npreferences by the distance between the mobile user and the merchant [8], but only set \nthe area based on the proximity of the distance and ignore the spatial activities of the \nmobile user [9]. However, these methods were limited to the analysis of user informa-\ntion and product information, and did not carefully consider the importance of user and \nbusiness location information. Therefore, the user preference model based on location \nrecommendation they created has some gap.\n\nConsidering the core of mobile marketing recommendation is location movement, \nLian et al. [10] proposed an implied feature-based cognitive feature collaborative filter-\ning (ICCF) framework, which avoids the impact of negative samples by combining con-\nventional methods and semantic content. In terms of algorithms, the author proposed \nan improved algorithm that can expand according to data size and feature size. To deter-\nmine the relevance of the project to user needs, Lee et al. [11] developed context infor-\nmation analysis and collaborative filtering methods for multimedia recommendations in \nmobile environments. Nevertheless, these methods only used small-scale training data \nand could not achieve accurate prediction of long-term interest for users. In this paper, \ndeep learning and time stamps are used to compensate for these shortcomings.\n\nWith great achievements in visual and speech tasks, the Deep Learning (DL) model \nhas become a novel field of study [12]. Because of the interventional optimization of \ndeep learning algorithms, artificial intelligence has made great breakthroughs in many \naspects. It is well known that models obtained through deep learning and machine learn-\ning models have very similar effects, which learns advanced abstract features from the \noriginal input features by simulating the network structure of the human nervous sys-\ntem. Experiments show that the deep model can express the characteristics of the data \nbetter than the shallow model [13]. Weight sharing by convolution makes CNN similar \nto biological neural networks, which reduces the difficulty of network structure and the \nnumber of weights. The structure of CNN is roughly divided into two layers. It is well \nknown that the first layer is a convolutional layer. Each neuron’s input is connected to the \nprevious layer through a convolution kernel and the local features are extracted. Next \nlayer is a pooling layer. In this layer, the neurons in the network are connected through \n\n\n\nPage 3 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\na convolution kernel to extract the overall features. Convolutional neural networks have \ngreat advantages in processing two-dimensional features [14], such as images.\n\nBased on our detailed comparative analysis, this paper proposes a location-based \nmobile marketing recommendation model by convolutional neural network (LBCNN). \nFirstly, we use user-product information as a training sample, and treat this problem as \na two-class problem. The category of the problem is divided into the purchase behav-\nior and the purchase behavior of the product at the next moment. In order to capture \nthe user’s timing preference characteristics, we divide the behavior of the merchandise \naccording to a certain length of time window and dig deeper into the behavior charac-\nteristics of each time window. Secondly, we consider the users’ timing preferences and \noverall preferences for the product. Then, the features of time window are used to train \nconvolutional neural network models. Finally, we input the sample features of the test \nset into the model and generate the Top-K sample as the location-based purchase fore-\ncast results [15].\n\nRemain of the paper is divided into four sections. Related work is shown in “Related \nwork” section. Necessary definitions and specific implementation of the location-based \nmobile marketing recommendation model by convolutional neural network (LBCNN) \nare shown in “Location-based mobile marketing recommendation model by CNN” sec-\ntion. In “Experimental analysis” section, experimental analysis is introduced. “Conclu-\nsion” section summarizes the strengths and weaknesses of the paper and proposes plans \nfor future progress.\n\nRelated work\nIn the current chapter, we will review existing methods for recommending systems \nthat can be broadly divided into three parts: content filtering, collaborative filtering \nand hybrid methods. We also discuss the establishment of feature models based on \ntime series to clearly represent the differences between our research and other existing \nmethods.\n\nTraditional recommendation method\n\nIn the general products recommendation system, the similarity between users is calcu-\nlated by the user’s interest feature vector. Then, the system recommends some products \nwith similarity greater than a certain threshold or the similar Top-N products to the tar-\nget user. This is a traditional recommendation algorithm based on content and the rec-\nommendation is based on comparing users.\n\na. Content‑based recommendation method\n\nContent-based information filtering has proven to be an effective application for \nlocating text documents related to topics. In particular, we need to focus on the \napplication of content-based information filtering in the recommendation system. \nContent-based methods allow for accurate comparisons between different texts \nor projects, so the recommended results are similar to the historical content of the \nuser’s consumption. The content-based recommendation algorithm involves the fol-\nlowing aspects. User description file describes the user’s preferences, which can be \nfilled by the user and dynamically updated based on the user’s feedback information \n\n\n\nPage 4 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\n(purchasing, reading, clicking, etc.) during the operation of the system. The project \nprofile describes the content characteristics of each project, which constitutes the \nfeature vector of the project. In addition, the similarity calculation is the similarity \nbetween the user’s description file and the item feature vector.\n\nThe similarity calculation of the content-based recommendation algorithm usually \nadopts the cosine similarity algorithm. The algorithm needs to calculate the similarity \nbetween the feature vector of user u and the feature vector of item i. The calculation \nformula is as shown in Formula (1).\n\nwhere ⇀u denotes the user feature vector, \n⇀\n\ni denotes the project feature vector, \n⇀\n\n|u| is the \nmodulus of the user feature vector and \n\n⇀\n\n|i| is the model of the project feature vector.\nRepresentative content-based recommendation systems mainly include Lops, \n\nGemmis, and Semeraro [16]. Compared to other methods, content-based recom-\nmendations have no cold-start issues and recommendations are easy to understand. \nHowever, the content filtering based recommendation method has various draw-\nbacks, such as strongly relying on the availability of content and ignoring the context \ninformation of the recommended party. The content-based recommendation method \nalso has certain requirements for the format of the project. Besides, it is difficult to \ndistinguish the merits of the project. The same type of project may have the same type \nof features, which are difficult to reflect the quality of the project.\n\nb. Collaborative filtering method\n\nThe recommendation based on collaborative filtering solves the recommendation \nproblem by using the information of similar users in the same partition to analyze and \nrecommend new content that has not been scored or seen by the target user.\n\nRegarding the traditional collaborative filtering method based on memory, we \nunderstand that this method is based on the different relationships between users and \nprojects. According to expert research, the traditional collaborative filtering method \nbased on memory should be divided into the following three steps.\n\nStep 1: collection of user behavior data, this step represents the user’s past behav-\nior with a m * n matrix R. The matrix Umn represents the feedback that the user m \nhas on the recommended object n. Rating is a range of values and different values \nrepresent how much the user likes the recommended object.\n\nStep 2: establishment of a user neighbor: establish mutual user relationships by \nanalyzing all user historical behavior data.\n\n(1)sim(u, i) =\n\n⇀\nu ·\n\n⇀\n\ni\n\n⇀\n\n|u|\n⇀\n\n|i|\n\nU =\n\n\n\n\n\n\n\nU11 U12 . . . U1n\n\nU21 U22 . . . U2n\n\n. . . . . . . . . . . .\n\nUm1 Um2 . . . Umn\n\n\n\n\n\n\n.\n\n\n\nPage 5 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nStep 3: generate recommendation results: find the most likely N objects from the rec-\nommended items selected by similar user sets.\n\nTherefore, recommendations are made by mining common features in similar users’ pref-\nerence information [17]. The normal methods in this classification include k-nearest neigh-\nbor (k-NN), matrix decomposition, and semi-supervised learning. According to the survey, \nAmazon uses an item-by-item collaborative filtering method to recommend personalized \nonline stores for each customer.\n\nCompared to other method, collaborative filtering has the ability to filter out informa-\ntion that can be automatically recognized by the machine and effectively use feedback from \nother similar users. However, collaborative filtering requires more ratings for the project, \nso it is affected by the issue of rating sparsity. In addition, this method does not provide a \nstandard recommendation for new users and new projects, which is called a cold start issue.\n\nc. Hybrid recommendation method\n\nThe hybrid recommendation method combines the above techniques in different ways to \nimprove the recommended performance and optimize the shortcomings of the conven-\ntional method. Projects that cannot be recommended for collaborative filtering are gener-\nally addressed by combining them with content-based filtering [18].\n\nThe core of this method is to independently calculate the recommendation results of the \ntwo types of recommendation algorithms, and then mix the results. There are two specific \nhybrid methods. One method is to mix the predicted scores of the two algorithms linearly. \nAnother hybrid method is to set up an evaluation standard, compare the recommended \nresults of the two algorithms, and take the recommendation results of the higher evaluation \nalgorithms. In general, the hybrid recommendation achieves a certain degree of compensa-\ntion between different recommendation algorithms. However, the hybrid recommendation \nalgorithm still needs improvement in complexity.\n\nd. Recommendation based on association rules\n\nThe association rule algorithm is a traditional data mining method that has been widely \nused in business for many years. The core idea is to analyze the rules of user historical \nbehavior data to recommend more similar behavioral items [19]. Rules can be either user-\ndefined or dynamically generated by using rule algorithms. The effect of the algorithm \ndepends mainly on the quantity and quality of the rules so the focus of the algorithm is on \nhow to develop high quality rules.\n\nDefine N as the total number of transactions, R is the total project and U and V are two \ndisjoint sets of items (U∩V ≠ ∅, U∈R, V∈R). The association rule is essentially an IF–Then \nstatement, here is expressed by U → V. The strength of the association rule U → V can be \nmeasured by two criteria: support and confidence. S is the ratio containing U and V data \nwhich both represent the number of transactions, which is shown in Formula (2).\n\nC is the ratio of U, V data to the only U data which represents the number of transac-\ntions, as shown in Formula (3)\n\n(2)S(U → V ) =\nN (U ∪ V )\n\nN\n.\n\n\n\nPage 6 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nThe recommendation process of the algorithm is shown in below.\nFirstly, according to the items of interest to the user, the user’s interest in other \n\nunknown items is predicted by rules. Secondly, compare the support of the rules. Finally, \nthe recommended items of TOP-N are obtained to the user.\n\nThe recommendation system based on association rules includes three parts: the key-\nword, the presentation and the user interface. The keyword layer is a set of keyword \nattributes and dependencies between keywords. The description layer connects the \nkeyword layer and the user layer and the main function is to describe the user and the \nresource. The user interface layer is the layer that interacts directly with the user. How-\never, the system becomes more and more difficult to manage as the rules increasing. In \naddition, there is a strong dependence on the quality of the rules and a cold start prob-\nlem is existed.\n\nMost of the recommendation systems use collaborative filtering algorithm to recom-\nmend for users. However, the traditional algorithm can only analyze ready-made data \nsimply, and most systems simply preprocess the data. In our method, we preprocess the \ndataset by extending the time information of the data to a time label. The next section is \nan explanation of the specific implementation.\n\nConstruction of time series behavior’s preference features\n\nThe timing recommendation model is based primarily on the Markov chain. This model \nmakes full use of timing behavior data to predict the next purchase behavior based on \nthe user’s last behavior. The advantage of this model is that it can generate good recom-\nmendations by timing behavior.\n\nAs shown in Fig. 1, the prediction problem of product purchase can be expressed as \npredicts the user’s purchase behavior at time T by a user behavior record set D before \ntime T [20]. Different actions occur at different times. For example, user1 visit location \na and b when user1 purchasing b and c at T − 3. We need to predict T-time consumer \nbehavior based on different timing behavior characteristics.\n\nAccording to relevant professional research, we divide the data sets of user behav-\nior into three groups in a pre-processing manner. By the feature statistics method, the \n\n(3)C(U → V ) =\nN (U ∪ V )\n\nN\n.\n\nFig. 1 The time series of user position feedback\n\n\n\nPage 7 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nfeatures are divided into two types, as shown in Table 1. “True” indicates that the feature \ngroup has corresponding features. Conversely, “False” means no such feature. Next we \nexplain these features.\n\na. Counting feature\n\nFor each feature statistics window, we use the behavioral counting feature and the de-\nduplication counting feature. The behavior count is a cumulative measure of the num-\nber of behaviors that occurred in and before the current window. For the location visit \nbehavior, it represents the number of visits to the product location by the user, the total \nnumber of visits by the user and the total number of visits to the merchandise. The de-\nduplication count feature is similar to the behavioral count, but only the number of non-\nrepetitive behavioral data is counted.\n\nb. Mean feature\n\nIn order to describe the activity of the user and the popularity of the product better, \nthis article derives a series of mean-type features based on the counting features. Take \nthe location visit behavior as an example, the user characteristics group includes the \nuser’s average number of visiting to the product. The average number of visiting to \nthe product by user i is calculated as shown in Formula (4).\n\nc. Ratio feature\n\nThe ratio of user-product behavior to the total behavior of the user and the product \nis also an aspect affecting the user’s degree of preference for the product. In the time \nwindow t, the method to calculate the ratio of the user’s visit to the products’ total \nvisit is shown in Formula (5).\n\nOur work presents a mobile marketing recommendation model is trained by adding \nthe time axis to the user position features. Contrary to current research, it is highly \nusable and low difficulty of achievement for real-world work applications. Consider-\ning the speed of calculation, we study the method of directly embedding time series \ninformation into the collaborative filtering calculation process to improve the recom-\nmendation quality. Specific information will be covered in the following sections.\n\n(4)avgui(t, i, visit) =\naction_count(t,U ,Ui, visit)\n\nuser_unique_item(t,U ,Ui, visit)\n.\n\n(5)rate_ui_in_u(t, i, j, visit) =\naction_count(t,UI ,Ui, Ij, visit)\n\naction_count(t,U ,Ui, visit)\n.\n\nTable 1 Characteristic system diagram (True/False)\n\nFeature group Counting feature Mean feature Ratio feature\n\nUser-product True False True\n\nUser feature True True False\n\nProduct feature True True False\n\n\n\nPage 8 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nLocation‑based mobile marketing recommendation model by CNN\nCreating the model is one of the most important aspects, which is an evaluation crite-\nrion to make sure correctness of the next step. This section mainly describes the rel-\nevant definitions of LBCNN that are shown in “Relevant definitions of the LBCNN” \nsection, and specific implementation of the model is shown in “Specific implementa-\ntion of the model” section.\n\nRelevant definitions of the LBCNN\n\nIn order to get better feature expression, we consider the user’s timing sensitivity of the \nproduct preferences and the user’s overall preferences comprehensively. This paper uses a \nconvolutional neural network as the basis to build location-based mobile marketing recom-\nmendation model. In the next step, we give the relevant definition.\n\na. Definition 1 (Model framework): based on the above analysis and user’s timing behav-\nior preference feature. We use the convolutional neural network model shown in Fig. 2. The \nmodel is divided into four layers that are input layer, multi-window convolution layer, pool-\ning layer and output layer. The input layer is a well-constructed input feature which trans-\nforms the input features into a two-dimensional plane by time series. Each time window is \nexpressed as an eigenvector. The multi-window convolutional layer convolves the input fea-\nture plane through different lengths of time windows to obtain different feature maps. The \npooling layer reduces the dimension of the feature map to obtain a pooled feature vector. \nThe output layer and the pooling layer are fully connected network structures.\n\nb. Definition 2 (Convolution layer): assume that there are N time windows of the feature \nand each time window has K user preference feature for the commodity. Then input sam-\nple × can be expressed as a matrix of T × K. The feature map in the convolutional layer is \ncalculated by the input layer and the convolution kernel. The window length of the convolu-\ntion kernel is h. xi,i+j represents the eigenvector added by time window i and time window \ni + j. The convolution kernel w can be expressed as a vector of h × K. Feature map f = [f1, f2, \n…, fT−h+1]. The i-th feature fi is calculated according to Formula (6):\n\n(6)fi = σ(w · xi,i+h−1 + b)\n\nFig. 2 The framework of the LBCNN\n\n\n\nPage 9 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nwhere b is an offset term and a real number. σ(x) is a nonlinear activation function. This \npaper uses ReLu and Tanh as an activation function. Relu is shown in Formula (7):\n\nc. Definition 3 (Max-pooling): the pooling layer is to scale the feature map while reduc-\ning the complexity of the network. The maximum features of the convolution kernel can \nbe obtained according to the maximum pooling operation. The feature map obtained \nat the kth product of the convolutional kernel is fk = [fk,1, fk,2, …, fk,T−h +1]. The pooling \noperation can be expressed as Formula (8):\n\nd. Definition 4 (Probability distribution): there are M convolution kernels and the output \nlayer has C categories [19]. The weight parameter θ of the output layer is a C × M matrix. \nThe pooled feature f̂ of x is an M-dimensional vector. The probability that x belongs to \nthe i-th category can be expressed as Formula (9):\n\nwhere bk represents the k-th offset of the fully connected layer. The loss function of the \nmodel can be obtained by the likelihood probability value, as shown in Formula (10):\n\nwhere T is the training data set, yi is the real category of the i-th sample, xi is the charac-\nteristic of the i-th sample and θ is the model’s parameters. We learn model parameters \nby minimizing the loss function. The training method adopts the improved gradient \ndescent method proposed by Zeiler. In addition, we have adopted Dropout process-\ning on the convolutional layer to prevent over-fitting of the trained model [21]. The \nDropout method randomizes the neurons in the convolutional layer to 0 with a certain \nprobability.\n\ne. Definition 5 (Latent factor): the value of the latent factor vector is true [22]. Whether \nan item belongs to a class is determined entirely by the user’s behavior. We assume that \ntwo items are liked by many users at the same time, then these two items have a high \nprobability of belonging to the same class. The weight of an item in a class can also be \ncalculated by itself. The implicit semantic model calculates the user’s (u) interest in the \nitem (i) are shown in Formula (11):\n\n(7)\nReLu = max(0, x).\n\nTanh(x) =\nex − e−x\n\nex + e−x\n.\n\n(8)Pool_feature(j) = down(fi).\n\n(9)p(i|x, θ) =\ne(θi·\n\n⌢\nf +bi)\n\n∑C\nk−1 e\n\n(θk ·\n⌢\nf +bk )\n\n(10)J (θ) = −\n\nk\n∑\n\ni=1\n\nlog(p(yi|x, θ))\n\n(11)R(u, i) = rui = pTu qi =\n\nF\n∑\n\nf=1\n\npu,kqi,k\n\n\n\nPage 10 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nwhere p is the relationship between the user interest and the kth implicit class. q is the \nrelationship between the kth implicit class and the item i. F is the number of hidden \nclasses, and r is the user’s interest in the item.\n\nSpecific implementation of the model\n\nWe can draw from Fig. 3 that the proposed model is divided into two processes. The first \nprocess is the training process and includes two parts. The top module shows how to gener-\nate CNN inputs and outputs from historical data. The other module in the training process \nshows that the traditional CNN parameters are trained by provided data. The second pro-\ncess finished a new location-based marketing resources recommendation. The recommen-\ndation process can work through the CNN parameters provided by the training process.\n\nTo achieve the features of users and location-based mobile marketing resources, the \nlatent factor model (LFM) is used. In traditional LFM, L2-norm regularization is often used \nto optimize training results. However, using L2-norm regularization often leads to excessive \nsmoothing problems. In our model, LFM results are used to represent the characteristics of \nthe training data. In this kind of thinking, we can learn from the training method of regres-\nsion coefficient in regression analysis, and construct a loss function. Therefore, it is more \nreasonable to use sparseness before the specification results. Based on these analyses, we \npropose an improved matrix decomposition method and try to normalize the solution by \n\nFig. 3 Location-based mobile marketing recommendation model by convolutional neural network\n\n\n\nPage 11 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nusing the premise of verifying the sparseness of the matrix. The model is presented as For-\nmula (12):\n\nThe next question is how to calculate these two parameters p and q. For the calculation \nof this linear model, this paper uses the gradient descent method. In the Formula (12), \n puk is a user bias item that represents the average of a user’s rating. qik is an item offset \nitem that represents the average of an item being scored. The offset term is an intrinsic \nproperty that indicates whether the item is popular with the public or a user is harsh \non the item. For positive samples, we specify ru,i = 1 based on experience and negative \nsample ru,i = 0, which is shown in Formula (11). The latter λ is a regularization term to \nprevent overfitting.\n\na. Description of the training section\n\nIn Fig. 3, If you want to train CNN, the first thing you need to solve is its input and out-\nput problems. For input, a language model is usually used.\n\nIn terms of output, we propose an improvement in model training by LFM, which is \nconstrained by the regularization of the L1-norm [23]. LFM training data is a historical \nscore between the user and the location-based marketing resources. The rating score can \nbe explicit because it is based on a user tag or an implied tag and it is predicted from the \nuser’s behavior. In this model, in order to ensure that the trained model is representative, \nthe training data we input is to select the existing authoritative standard training set.\n\nb. Description of the recommended part\n\nOnce the LBCNN model structure is established and the model parameters are trained \nusing the training data set, the recommended real-time performance can be achieved. \nThe real-time performance is based on the update of network model parameters in the \nbackground, and it uses some past behavior data and information of the recommended \npeople and products.\n\nUser information and product information can be obtained in advance and digitized. \nIn the offline training model phase, digitized user information, product information, and \nbehavior information are utilized [24]. The same model is trained for the same type of \nusers, and the parameters of the model are periodically updated within a certain period \nof time. In the real-time recommendation stage, real-time recommendation can be real-\nized only by integrating the collected behavior data with the previous data and inputting \nit into the model.\n\nExperimental analysis\nIn order to verify the advantages of convolutional neural network in capturing user’s \ntiming preferences for product and mining users’ temporal behavior characteristics, \nwe compare several commonly used classification models under the same conditions of \ntraining features. They are Linear Logistic Regression Classification Model (LR), Support \n\n(12)J (U ,V ) =\n∑\n\nu,i∈K\n\n(\n\nru,i −\n\nk\n∑\n\nk=1\n\npu,kqi,k\n\n)2\n\n+   puk \n2 +   qik \n\n2.\n\n\n\nPage 12 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nVector Machine (SVM), Random Forest Model (RF) and Gradient Boosting Regression \nTree Model (GBDT) [25]. We also compare the products that have been visited for the \nlast 8 h. Experimental tool is sklearn kit. The hyper parameter settings for each model \nduring the experiment are:\n\na. LR: select L2 regular and the regularization coefficient is 0.1.\nb. SVM: choose radial basis kernel function (RBF) and gamma of kernel function is \n\n0.005.\nc. RF: the number of trees is 200, the entropy is selected as the feature segmentation \n\nstandard and the random feature ratio is 0.5.\nd. GBDT: the number of trees is 100, the learning rate is 0.1 and the maximum depth of \n\nthe tree is 3.\n\nDescription of the data set\n\nThe experiment in our paper uses the dataset disclosed according to the Alibaba Group’s \nmobile recommendation algorithm contest held in 2015. This data set contains 1 month \nof user behavior data and product information. The user’s behavior data includes 10 mil-\nlion users’ various behaviors on 2,876,947 items. Behavior types include clicks, shopping \ncarts and purchases. In addition, each behavior record identifies behavior time that is \naccurate to the hour. The product information includes product category information, \nand identifies whether the product is an online to offline type. In a real business sce-\nnario, we often need to build a personalized recommendation model for a subset of all \nproducts. In the process of completing this task, we not only need to take advantage of \nthe user’s behavior data on this subset of goods, but also need to use more abundant user \nbehavior data. We need to define the following symbols: U (User collection), I (Product \ncollection), P (Product subset, P ⊆ I), D (User behavior data collection for the complete \nset of products). Our goal is to use D to construct a recommendation model for users in \nU to products in P.\n\nThe data mainly consists of two parts. The first part is the mobile behavior data (D) of \n10 million users on the product collection, including the following fields, as shown in \nTable 2.\n\nFor example, “141278390, 282725298, 1, 95jnuqm, 5027, 2014-11-18 08” is one of \nthe data. The Behavior_type and the Time in these fields contain the largest amount \n\nTable 2 The mobile behavior data of the Ali mobile recommendation data set\n\nField Field description Extraction instruction\n\nUser_id User differentiation Sampling and data masking\n\nItem_id Product differentiation Data masking\n\nBehavior_type The type of behavior of the user on the \nproduct\n\nIncluding browsing, collecting, adding shop-\nping carts, and purchasing, the values are 1, 2, \n3, 4 respectively\n\nUser_geoinfo The spatial reference identifier of the user’s \nlocation\n\nFormed by latitude and longitude data through \na secret algorithm\n\nItem category Product classification identifier Field masking\n\nTime Action time Accurate to hour level\n\n\n\nPage 13 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nof information. The User_geohash field is basically unusable due to too many missing \nvalues.\n\nThe second part is the product subset (P), which contains the following fields, as \nshown in Table 3.\n\nSimilar to the above, “117151719, 96ulbnj, 7350” is one of the product information. \nThe training data contains the mobile behavior data (D) of a sample of a certain user \nwithin 1 month (11.18–12.18). The scoring data is the purchase data of the product sub-\nset (P) by these users 1 day (12.19) after this 1 month. We should be training the data \nmodel to output the predicted results of the user’s purchase behavior on the next day.\n\nData preprocessing\n\nWe found that there are some users have a lot of page views (maximum of 2 million), which \nis beyond reasonable levels. We analyze that these users may be crawler users, so the behav-\nior of these users on the goods is not the basis for predicting the user’s purchase. At the \nsame time, we predict the user product pairs that have appeared in all historical records. \nThe existence of these users will undoubtedly increase our forecasting amount and interfere \nwith our normal model training. Therefore, we choose to filter out these users, the filtering \nrules are shown as Fig. 4.\n\nTable 3 The product subset of the Ali mobile recommendation data set\n\nField Field description Extraction instruction\n\nItem_id Product differentiation Sampling and data masking\n\nItem_geohash Spatial information of the product location, \nwhich can be empty\n\nFormed by latitude and longi-\ntude data through a secret \nalgorithm\n\nItem_category Product classification identifier Data masking\n\nFig. 4 Data filtering rules\n\n\n\nPage 14 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nEvaluation index\n\nThe purpose of the proposed method is to predict the user’s purchased business in the next \nposition based on the user’s historical behavior record. Therefore, we evaluate the model \nwith the data of the last day. The sample construction of time series method is shown in \nFig.  1. F1-score can be viewed as a harmonic mean of accuracy and recall. At present, \nF1-score has been widely used in the evaluation of the recommendation system.\n\nwhere Formula (13) is the calculation method of the accuracy rate, Formula (14) is the \ncalculation method of the recall rate, and Formula (15) is the calculation method of \nF1-score. Prediction_set is the predicted purchase of the user-item. Answer_set is a real-\npurchased user-item collection.\n\nThe distribution of positive and negative samples used in this experiment is extremely \nunbalanced, and negative samples contain more noise. In order to make the model more \nsuitable for learning under unbalanced data, we perform under sampling on negative \nsamples. The model training process adopts AdaDelta Update Rule to adjust the param-\neters by using the stochastic gradient descent method. Hyper Parameters of the model \nare described in Table 4. The value in the table is the final hyper parameter when the \nerror of the validation set is minimal. Convolution time window in convolution kernel \nis 2 and 3. The number of convolution kernels for two different length windows is 200. \nIn this experiment, the training process needs to iterate ten times. To achieve the con-\nvergence of the model, we observe the accuracy of the training set every iteration in the \nmodel training process.\n\nIn Fig. 5, the abscissa indicates the number of iterations, and the ordinate indicates the \naccuracy of the sample. As we can see from the figure, the accuracy of the training set \nhas been increasing and the verification set accuracy has declined after the fifth iteration \nof the model [26]. This situation shows that the model training has been overfitting after \n\n(13)precision =\n\n∣\n\n∣prediction_set ∩ answer_set\n∣\n\n∣\n\n∣\n\n∣prediction_set\n∣\n\n∣\n\n(14)Recall =\n\n∣\n\n∣prediction_set ∩ answer_set\n∣\n\n∣\n\n|answer_set|\n\n(15)F1− score =\n2× precision× recall\n\nprecision+ recall\n\nTable 4 Parameter settings of convolutional neural networks\n\nParameter name Parameter value\n\nActivation function of convolution kernel Tanh\n\nSize of convolution kernel window [2, 3]\n\nNumber of convolution kernel 400\n\nDropout ratio 0.5\n\nBatch size 64\n\nEpoch 5\n\n\n\nPage 15 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nthe 5th iteration. In addition, we found that the test set accuracy is higher than the train-\ning set and verification set.\n\nExperimental results and comparison\n\nThe experimental results obtained using the above parameters are shown in Table 5. As \ncan be seen from Table  5, the machine learning model using the features designed in \nthis paper is superior to the traditional method. Our model achieves an 80% accuracy \nin predicting the accuracy of user behavior, which is significantly better than traditional \nmodels at least 10%. In terms of recall rate, LBCNN reached 8.14%, which is at least 2% \nhigher than the traditional method. Similarly, our model is up to 8.07% in F1-score.\n\nThis result shows that the user’s time-series behavior preference model is reasonable. \nThis solution works well for improving the accuracy and quality of recommendations. In \na single model, the LBCNN model works best. Since the linear model assumes that each \nfeature is independent, it is impossible to excavate the intrinsic relationship between \nfeatures. The proposed method can mine the intrinsic link between user timing prefer-\nence features better. The experimental results show that the user preferences we build \nare more accurate and convolutional neural networks have strong capabilities of feature \nextraction and model generalization.\n\nFig. 5 Training process of the LBCNN\n\nTable 5 Comparing the experimental results of each model (%)\n\nModel Accuracy Recall rate F1-score\n\nTraditional method 31.4 5.60 4.02\n\nLR 75.0 7.63 7.57\n\nSVM 70.0 7.12 7.06\n\nRF 57.5 5.85 5.80\n\nGBDT 62.5 6.36 6.13\n\nLBCNN 80.0 8.14 8.07\n\n\n\nPage 16 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\nConclusion\nThe current mobile marketing recommendation system only treats location informa-\ntion as a recommended attribute, which weakens the role of the location information in \nthe recommendation. For the implicit feedback behavior of users, this paper proposes \na location-based mobile marketing method by convolutional neural network. First, we \ndivide the user location-based behaviors into several time windows according to the \ntimestamp of these behaviors, and model the user preference in different dimensions \nfor each window. Then we utilize the convolutional neural network to train a classifier. \nFinally, the experimental process of this paper is introduced, and a good prediction effect \nis obtained on effective data sets. The final experimental results express that the pro-\nposed method has different feature extraction perspectives from other models. Because \nof using convolutional neural networks, the proposed method has stronger capability \nof feature extraction and generalization. This method helps to change the accuracy and \nquality of the recommendation system and user satisfaction.\n\nThe work introduced here is to show the prospects for further research. The method \nproposed in this paper has a certain dependence on the user’s geographical location \ninformation during the training process of the user preference model. In addition, the \nrecommendation system will encounter a cold-start problem with sparse user infor-\nmation. For dealing with these discovered issues, we plan to use the hot start case to \nimprove the recommended cold start problem. Meanwhile, we are investigating new \nmethod which uses a better big data framework (such as Hadoop MapReduce) to ensure \nthe efficiency of training large data sets. In the future, we will show recommended meth-\nods to improve performance in other applications.\nAuthors’ contributions\nCY conceptualized the study and analyzed all the data. SD performed all experiments and wrote the manuscript. JW \nadvised on the manuscript preparation and technical knowledge. All authors read and approved the final manuscript.\n\nAuthor details\n1 School of Computer and Software, Jiangsu Engineering Center of Network Monitoring, Nanjing University of Informa-\ntion Science & Technology, Nanjing 210044, China. 2 School of Computer & Communication Engineering, Changsha \nUniversity of Science & Technology, Changsha 410004, China. \n\nAcknowledgements\nIt was supported by the Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD), Post-\ngraduate Research & Practice Innovation Program of Jiangsu Province (KYCX18_1032).\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nWe declared that materials described in the manuscript will be freely available to any scientist wishing to use them for \nnon-commercial purposes.\n\nFunding\nThis work was supported by the National Natural Science Foundation of China (61772282, 61772454, 61811530332, \n61811540410).\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 25 September 2018 Accepted: 4 April 2019\n\nReferences\n 1. Fernández-Tobías I, Braunhofer M, Elahi M, Ricci F, Cantador I (2016) Alleviating the new user problem in collabora-\n\ntive filtering by exploiting personality information. User Model User Adap Inter 26(2–3):221–255\n\n\n\nPage 17 of 17Yin et al. Hum. Cent. Comput. Inf. Sci. (2019) 9:14 \n\n 2. Koohi H, Kiani K (2016) User based collaborative filtering using fuzzy C-means. Measurement 91:134–139\n 3. Xu X, Fu S, Qi L, Zhang X, Liu Q, He Q, Li S (2018) An IoT-oriented data placement method with privacy preservation \n\nin cloud environment. J Netw Comput Appl 124:148–157\n 4. Yingyuan X, Pengqiang A, Ching-Hsien H, Hongya W, Xu J (2015) Time-ordered collaborative filtering for news \n\nrecommendation. China Commun 12(12):53–62\n 5. Kaminskas M, Ricci F (2011) Location-adapted music recommendation using tags. In: International conference on \n\nuser modeling, adaptation, and personalization. pp 183–194\n 6. Zhu H, Chen E, Xiong H, Yu K, Cao H, Tian J (2015) Mining mobile user preferences for personalized context-aware \n\nrecommendation. ACM Trans Intell Syst Technol TIST 5(4):58\n 7. Yin H, Cui B, Chen L, Hu Z, Zhang C (2015) Modeling location-based user rating profiles for personalized recommen-\n\ndation. ACM Trans Knowl Discov Data TKDD 9(3):19\n 8. Li X, Xu G, Chen E, Li L (2015) Learning user preferences across multiple aspects for merchant recommendation. In: \n\n2015 IEEE international conference on data mining (ICDM). pp 865–870\n 9. Yin C, Xi J, Sun R, Wang J (2018) Location privacy protection based on differential privacy strategy for big data in \n\nindustrial internet-of-things. IEEE Trans Industr Inf 14(8):3628–3636\n 10. Lian D, Ge Y, Zhang F, Yuan NJ, Xie X, Zhou T, Rui Y (2015) Content-aware collaborative filtering for location recom-\n\nmendation based on human mobility data. In: 2015 IEEE international conference on data mining. pp 261–270\n 11. Lee WP, Tseng GY (2016) Incorporating contextual information and collaborative filtering methods for multimedia \n\nrecommendation in a mobile environment. Multimedia Tools Appl 75(24):16719–16739\n 12. Bengio Y (2009) Learning deep architectures for AI. Found Trends Mach Learn 2(1):1–127\n 13. LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436–444\n 14. Yuan C, Li X, Wu QJ, Li J, Sun X (2017) Fingerprint liveness detection from different fingerprint materials using convo-\n\nlutional neural network and principal component analysis. Comput Mater Continua 53(4):357–372\n 15. Yin C, Wang J, Park JH (2017) An improved recommendation algorithm for big data cloud service based on the trust \n\nin sociology. Neurocomputing 256:49–55\n 16. Längkvist M, Karlsson L, Loutfi A (2014) A review of unsupervised feature learning and deep learning for time-series \n\nmodeling. Pattern Recogn Lett 42:11–24\n 17. Tu Y, Lin Y, Wang J, Kim JU (2018) Semi-supervised learning with generative adversarial networks on digital signal \n\nmodulation classification. Comput Mater Continua 55(2):243–254\n 18. Nilashi M, Bin Ibrahim O, Ithnin N (2014) Hybrid recommendation approaches for multi-criteria collaborative filter-\n\ning. Expert Syst Appl 41(8):3879–3900\n 19. Zeng D, Dai Y, Li F, Sherratt RS, Wang J (2018) Adversarial learning for distant supervised relation extraction. Comput \n\nMater Continua 55(1):121–136\n 20. Yin C, Xia L, Zhang S, Sun R, Wang J (2018) Improved clustering algorithm based on high-speed network data \n\nstream. Soft Comput 22(13):4185–4195\n 21. Krizhevsky A, Sutskever I, Hinton GE (2012) Imagenet classification with deep convolutional neural networks. In: \n\nAdvances in neural information processing systems, pp 1097–1105\n 22. Li X, Yao C, Fan F, Yu X (2017) A text similarity measurement method based on singular value decomposition and \n\nsemantic relevance. J Inf Process Syst 13(4):863–875\n 23. Li CN, Shao YH, Deng NY (2015) Robust L1-norm two-dimensional linear discriminant analysis. Neural Networks \n\n65:92–104\n 24. Fattah MA (2017) A novel statistical feature selection approach for text categorization. J Inf Process Syst \n\n13(5):1397–1409\n 25. Wang Y, Feng D, Li D, Chen X, Zhao Y, Niu X (2016) A mobile recommendation system based on logistic regression \n\nand Gradient Boosting Decision Trees. In: International joint conference on neural networks. pp 1896–1902\n 26. Yin C, Zhang S, Xi J, Wang J (2017) An improved anonymity model for big data security based on clustering algo-\n\nrithm. Concurr Comput Pract Exp 29(7):e3902\n\n\n\tMobile marketing recommendation method based on user location feedback\n\tAbstract \n\tIntroduction\n\tRelated work\n\tTraditional recommendation method\n\ta. Content-based recommendation method\n\tb. Collaborative filtering method\n\tc. Hybrid recommendation method\n\td. Recommendation based on association rules\n\n\tConstruction of time series behavior’s preference features\n\ta. Counting feature\n\tb. Mean feature\n\tc. Ratio feature\n\n\n\tLocation-based mobile marketing recommendation model by CNN\n\tRelevant definitions of the LBCNN\n\tSpecific implementation of the model\n\ta. Description of the training section\n\tb. Description of the recommended part\n\n\n\tExperimental analysis\n\tDescription of the data set\n\tData preprocessing\n\tEvaluation index\n\tExperimental results and comparison\n\n\tConclusion\n\tAuthors’ contributions\n\tReferences\n\n\n\n\n", "metadata_storage_path": "aHR0cHM6Ly9jb3Vyc2VjYXRhbG9nc3RvcmFnZW5yai5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3MxMzY3My0wMTktMDE3Ny02LnBkZg2", "metadata_title": "Mobile marketing recommendation method based on user location feedback", "keyphrases": [ "Mobile marketing recommendation method", "user location feedback" ], "pubication_name": null, "publishers": null, "doi": null, "publication_date": null } ] }
